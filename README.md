# City Segmentation with GAN Pix2Pix

This project involves the segmentation of city images using a Generative Adversarial Network (GAN) based on the Pix2Pix model. The model was trained for 350 epochs with a dataset of 3200 images.

## Screenshot
<br>
<img width="620" alt="Screenshot 2024-06-26 at 11 10 08â€¯AM" src="https://github.com/Abhigyan126/City-Segmentation/assets/108809711/6705ba3e-7aac-49ef-8bb6-11f25ff6d877">

<br>
## Introduction

The goal of this project is to accurately segment images of cityscapes into different classes such as buildings, roads, and sky. We use the Pix2Pix model, a type of conditional GAN, which is well-suited for image-to-image translation tasks.

## Dataset

The dataset used for training consists of 3200 images of cityscapes. Each image has corresponding ground truth segmentation masks. The dataset can be found on Kaggle: [Cityscapes Image Pairs](https://www.kaggle.com/datasets/dansbecker/cityscapes-image-pairs).

